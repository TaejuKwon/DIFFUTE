{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from Levenshtein import ratio\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_begin = 44032\n",
    "kor_end = 55203\n",
    "chosung_base = 588\n",
    "jungsung_base = 28\n",
    "jaum_begin = 12593\n",
    "jaum_end = 12622\n",
    "moum_begin = 12623\n",
    "moum_end = 12643\n",
    "\n",
    "chosung_list = [ 'ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', \n",
    "        'ㅅ', 'ㅆ', 'ㅇ' , 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jungsung_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', \n",
    "        'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', \n",
    "        'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', \n",
    "        'ㅡ', 'ㅢ', 'ㅣ']\n",
    "\n",
    "jongsung_list = [\n",
    "    ' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ',\n",
    "        'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', \n",
    "        'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', \n",
    "        'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jaum_list = ['ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄸ', 'ㄹ', \n",
    "              'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', \n",
    "              'ㅃ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "moum_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', \n",
    "              'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "\n",
    "def compose(chosung, jungsung, jongsung):\n",
    "    char = chr(\n",
    "        kor_begin +\n",
    "        chosung_base * chosung_list.index(chosung) +\n",
    "        jungsung_base * jungsung_list.index(jungsung) +\n",
    "        jongsung_list.index(jongsung)\n",
    "    )\n",
    "    return char\n",
    "\n",
    "def decompose(c):\n",
    "    if not character_is_korean(c):\n",
    "        return None\n",
    "    i = ord(c)\n",
    "    if (jaum_begin <= i <= jaum_end):\n",
    "        return (c, ' ', ' ')\n",
    "    if (moum_begin <= i <= moum_end):\n",
    "        return (' ', c, ' ')\n",
    "\n",
    "    # decomposition rule\n",
    "    i -= kor_begin\n",
    "    cho  = i // chosung_base\n",
    "    jung = ( i - cho * chosung_base ) // jungsung_base \n",
    "    jong = ( i - cho * chosung_base - jung * jungsung_base )    \n",
    "    return (chosung_list[cho] + jungsung_list[jung] + jongsung_list[jong])\n",
    "\n",
    "def character_is_korean(c):\n",
    "    i = ord(c)\n",
    "    return ((kor_begin <= i <= kor_end) or\n",
    "            (jaum_begin <= i <= jaum_end) or\n",
    "            (moum_begin <= i <= moum_end))\n",
    "    \n",
    "def decompose_string(s):\n",
    "    return ''.join([decompose(c) for c in s if character_is_korean(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ㄴㅑㅁㄴㅑㅁ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose_string('냠 냠')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar Korean onomatopoeia: 싱긋, English Translation:  Grinning\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance as lev_distance\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/mnt/c/Users/USER/LABis/DiffUTE/Onomatopoeia/korean_English_Onomatopoeia.csv', header=None)\n",
    "df.columns = ['Korean Onomatopoeia', 'English Translation']\n",
    "\n",
    "def find_similar_korean_onomatopoeia(input_word):\n",
    "    min_distance = float('inf')\n",
    "    most_similar = None\n",
    "    english_translation = None\n",
    "    decomposed_input = decompose_string(input_word)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        korean_word = row['Korean Onomatopoeia']\n",
    "        decomposed_korean_word = decompose_string(korean_word)\n",
    "        distance = lev_distance(decomposed_input, decomposed_korean_word)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            most_similar = korean_word\n",
    "            english_translation = row['English Translation']\n",
    "\n",
    "    return most_similar, english_translation\n",
    "\n",
    "# Example usage\n",
    "input_korean_word = '상곳'  # Replace with your input Korean word\n",
    "similar_korean_word, its_translation = find_similar_korean_onomatopoeia(input_korean_word)\n",
    "print(f\"Most similar Korean onomatopoeia: {similar_korean_word}, English Translation: {its_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['싱긋', '턱', '터벅', '가나다라마바사', '끼개각']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Onomatopoeia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minput_similar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_most_similar_word_from_OCR\n\u001b[1;32m      3\u001b[0m find_most_similar_word_from_OCR(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m끼기긱\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/USER/LABis/DiffUTE/Onomatopoeia/input_similar.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLevenshtein\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance \u001b[38;5;28;01mas\u001b[39;00m lev_distance\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOnomatopoeia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mOnomato_translation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decompose_string\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_most_similar_word_from_OCR\u001b[39m(input_word, words_list):\n\u001b[1;32m      7\u001b[0m     min_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Onomatopoeia'"
     ]
    }
   ],
   "source": [
    "from input_similar import find_most_similar_word_from_OCR\n",
    "\n",
    "find_most_similar_word_from_OCR('끼기긱', list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textdiffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
